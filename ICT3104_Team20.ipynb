{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junweilam/ICT3104_T20/blob/main/ICT3104_Team20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnBEtHGTkZmq"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRx8WYKj4wmi"
      },
      "source": [
        "**Installing of necessary dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkfrriZG8HkP"
      },
      "outputs": [],
      "source": [
        "!pip install ipywidgets==7.6.3\n",
        "!pip install pyyaml\n",
        "!pip install opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3L3k0RL9RMN"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-_qM8wp46Jd"
      },
      "source": [
        "**Installation for Debugger**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hv-YNQycugJz"
      },
      "outputs": [],
      "source": [
        "#Debugger\n",
        "!pip install -Uqq ipdb\n",
        "import ipdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-omKrkiU5F9d"
      },
      "source": [
        "**Debugger Switch (On/Off)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtHiKNusu7Rx"
      },
      "outputs": [],
      "source": [
        "# Turn On Debugger\n",
        "%pdb on\n",
        "\n",
        "# Turn Off Debugger\n",
        "# %pdb off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiQtjQsw6t8w"
      },
      "source": [
        "# **Uploading Of Input Video File in .mp4 format** (T20-1)\n",
        "1.   Run the cell and click the \"Upload\" button to upload a video in .mp4 format\n",
        "2.   Once file is selected, click \"Save MP4\" button to save the .mp4 file\n",
        "3.   File is saved when progress bar is 100% green and \"Save MP4\" button is changed to \"MP4 Saved!\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHMf5Mumjzuz"
      },
      "outputs": [],
      "source": [
        "# Testing.ipynb\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import os\n",
        "import shutil\n",
        "import asyncio\n",
        "import platform\n",
        "import time\n",
        "from base64 import b64encode\n",
        "\n",
        "\n",
        "# Create a file uploader widget\n",
        "file_upload = widgets.FileUpload(\n",
        "    accept='.mp4',\n",
        "    multiple=False\n",
        ")\n",
        "\n",
        "# Create a button widget\n",
        "save_button = widgets.Button(\n",
        "    description=\"Save MP4\",\n",
        "    disabled=False,\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "# Create a progress widget\n",
        "progress = widgets.FloatProgress(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=100,\n",
        "    bar_style=\"success\"\n",
        ")\n",
        "\n",
        "def update_progress_bar():\n",
        "  progress.value += 25\n",
        "  time.sleep(1)\n",
        "\n",
        "def save_mp4(b):\n",
        "    if file_upload.value:\n",
        "        # Get the uploaded file\n",
        "        uploaded_file = list(file_upload.value.values())[0]\n",
        "\n",
        "        update_progress_bar()\n",
        "\n",
        "        # Specify the destination folder to save the file\n",
        "        destination_folder = './input/'\n",
        "\n",
        "        update_progress_bar()\n",
        "\n",
        "        # Create the destination folder if it doesn't exist\n",
        "        if not os.path.exists(destination_folder):\n",
        "            os.makedirs(destination_folder)\n",
        "\n",
        "        update_progress_bar()\n",
        "\n",
        "        with open(os.path.join(destination_folder, uploaded_file['metadata']['name']), 'wb') as f:\n",
        "            f.write(uploaded_file['content'])\n",
        "\n",
        "        update_progress_bar()\n",
        "\n",
        "        # Disable the file uploaded and update the button text\n",
        "        file_upload.disabled = True\n",
        "        save_button.description = \"MP4 Saved!\"\n",
        "    else:\n",
        "        print(\"Please upload an MP4 file first\")\n",
        "\n",
        "display(file_upload, save_button, progress)\n",
        "\n",
        "save_button.on_click(save_mp4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Viewing of uploaded videos** (T20-21)\n",
        "\n",
        "1.   Select a video uploaded from the dropdown list\n",
        "2.   Click the \"Play Video\" button to display and view the video"
      ],
      "metadata": {
        "id": "3PKSwC8uCzjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing .ipynb\n",
        "import os\n",
        "from IPython.display import Video, display, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# Path to the input directory\n",
        "input_directory = './input'\n",
        "video_files = []\n",
        "if os.path.exists(input_directory):\n",
        "  # Get a list of video files in the input directory\n",
        "  video_files = [file for file in os.listdir(input_directory) if file.endswith('.mp4')]\n",
        "\n",
        "# Create a dropdown widget with video file options\n",
        "video_dropdown = widgets.Dropdown(\n",
        "    options=video_files,\n",
        "    description='Select Video:'\n",
        ")\n",
        "\n",
        "\n",
        "# Create a button widget for playing the selected video\n",
        "play_button = widgets.Button(description=\"Play Video\")\n",
        "\n",
        "# Function to handle button click event\n",
        "def play_video(event):\n",
        "    selected_video = video_dropdown.value\n",
        "    video_path = os.path.join(input_directory, selected_video)\n",
        "    # display(Video(video_path, width=640, height=360))  # Adjust width and height as needed\n",
        "\n",
        "    # For Google Collab\n",
        "    mp4 = open(video_path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(\"\"\"<video width=400 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % data_url))\n",
        "\n",
        "\n",
        "# Attach the function to the button's click event\n",
        "play_button.on_click(play_video)\n",
        "\n",
        "# Display the dropdown and button widgets\n",
        "display(video_dropdown)\n",
        "display(play_button)"
      ],
      "metadata": {
        "id": "J6NQAkI4C0xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a pose skeleton(MMPose) of the character in the video doing the same action. (T20-4)"
      ],
      "metadata": {
        "id": "yK0gyiyRDiUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %pip install -U openmim\n",
        "# !mim install mmengine\n",
        "# !mim install \"mmcv>=2.0.0\"\n",
        "# !mim install \"mmdet>=3.0.0\""
      ],
      "metadata": {
        "id": "RIBQGazcDlEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install MMPose from source"
      ],
      "metadata": {
        "id": "GjBLWoBcDqpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content\n",
        "# !git clone https://github.com/open-mmlab/mmpose.git\n",
        "# %cd mmpose\n",
        "# !pip install -e ."
      ],
      "metadata": {
        "id": "5njMN74ODpFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Demo (2D Human Whole-Body Pose Estimation with Inferencer)\n",
        "\n",
        "‚ùó Rename the mp4 to your video accordingly for now"
      ],
      "metadata": {
        "id": "OvhIFTJyDucf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/mmpose\n",
        "\n",
        "# !python demo/inferencer_demo.py ../input/man-surfing.mp4 --black-background --pose2d human --vis-out-dir vis_results/posetrack18"
      ],
      "metadata": {
        "id": "dMJ9krbgDuwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import os\n",
        "\n",
        "# Define a function to run the pose estimation\n",
        "def run_pose_estimation(video_path, black_background, pose2d, vis_out_dir):\n",
        "    cmd = f\"python demo/inferencer_demo.py {video_path} --black-background --pose2d {pose2d} --vis-out-dir {vis_out_dir}\"\n",
        "    if black_background:\n",
        "        cmd += \" --black-background\"\n",
        "    os.system(cmd)\n",
        "\n",
        "# Specify the input directory where your video files are located\n",
        "input_directory = '../input'\n",
        "\n",
        "# Check if the input directory exists\n",
        "if os.path.exists(input_directory):\n",
        "    # Get a list of video files in the input directory\n",
        "    video_files = [os.path.join(input_directory, file) for file in os.listdir(input_directory) if file.endswith('.mp4')]\n",
        "else:\n",
        "    video_files = []\n",
        "\n",
        "# Create a dropdown widget to select a video\n",
        "video_selector = widgets.Dropdown(\n",
        "    options={os.path.basename(video_file): video_file for video_file in video_files},\n",
        "    description='Select Video:',\n",
        ")\n",
        "\n",
        "\n",
        "# Create other widgets for additional options\n",
        "black_background_checkbox = widgets.Checkbox(value=True, description='Black Background')\n",
        "pose2d_selector = widgets.Dropdown(\n",
        "    options=['human', 'other_pose_option'],\n",
        "    description='Pose2D:',\n",
        ")\n",
        "vis_out_dir_text = widgets.Text(value='vis_results/posetrack18', description='Output Directory:')\n",
        "\n",
        "# Create a button to trigger the pose estimation\n",
        "run_button = widgets.Button(description='Run Pose Estimation')\n",
        "\n",
        "# Define an event handler for the button click\n",
        "def run_button_click(b):\n",
        "    video_path = video_selector.value\n",
        "    black_background = black_background_checkbox.value\n",
        "    pose2d = pose2d_selector.value\n",
        "    vis_out_dir = vis_out_dir_text.value\n",
        "    run_pose_estimation(video_path, black_background, pose2d, vis_out_dir)\n",
        "\n",
        "run_button.on_click(run_button_click)\n",
        "\n",
        "# Display the widgets\n",
        "display(video_selector, black_background_checkbox, pose2d_selector, vis_out_dir_text, run_button)"
      ],
      "metadata": {
        "id": "ExEY0d9DDwkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generating Skeleton based on video selected\n",
        "# Pose - Pose Skeleton Creation\n",
        "# %pip install ipywidgets\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from base64 import b64encode\n",
        "import time  # Import the time module\n",
        "import subprocess\n",
        "\n",
        "%cd /content\n",
        "if not os.path.exists('./mmpose'):\n",
        "  %pip install -U openmim\n",
        "  !mim install mmengine\n",
        "  !mim install \"mmcv>=2.0.0\"\n",
        "  !mim install \"mmdet>=3.0.0\"\n",
        "  !git clone https://github.com/open-mmlab/mmpose.git\n",
        "  %cd mmpose\n",
        "  !pip install -e .\n",
        "  %cd /content\n",
        "\n",
        "# add dropdown to allow selection of poses\n",
        "list_of_poses = []\n",
        "input_folder = \"./input\"\n",
        "if os.path.exists(input_folder):\n",
        "  for file in os.listdir(input_folder):\n",
        "    if file.endswith(\".mp4\"):\n",
        "        list_of_poses.append(file)\n",
        "\n",
        "# Widget Dropdown\n",
        "pose_dropdown = widgets.Dropdown(\n",
        "    options=list_of_poses,\n",
        "    description='Select a MP4 File:'\n",
        ")\n",
        "\n",
        "section_label = widgets.HTML(value='<h2 style=\"font-size: 20px;\">Generating Skeleton </h2>')\n",
        "\n",
        "# Create a button widget\n",
        "button = widgets.Button(description=\"Generate Skeleton\")\n",
        "\n",
        "def display_video(video_path):\n",
        "    with open(video_path, \"rb\") as f:\n",
        "        video_data = f.read()\n",
        "        video_base64 = b64encode(video_data).decode(\"utf-8\")\n",
        "        video_html = f'<video controls width=\"400\"><source src=\"data:video/mp4;base64,{video_base64}\" type=\"video/mp4\"></video>'\n",
        "        display(HTML(video_html))\n",
        "    display_message('Video Generated!')\n",
        "\n",
        "def display_loading():\n",
        "    loading_message = HTML('<p>Video Generating... Please Wait...</p>')\n",
        "    display(loading_message)\n",
        "    # Simulate video generation with a sleep\n",
        "    time.sleep(3)  # Sleep for 3 seconds [Will help to let users know the video is generating.]\n",
        "\n",
        "# Annouce to user that video is done and can input another prompt\n",
        "def display_message(message):\n",
        "    loading_message = HTML('<p>' + message + '</p>')\n",
        "    display(loading_message)\n",
        "\n",
        "def save_skeleton(): # TODO! FIX COMMAND\n",
        "    # Specify the full path to the input video and output directory\n",
        "    input_video = '../input/' + pose_dropdown.value\n",
        "    output_dir = 'vis_results/posetrack18'\n",
        "\n",
        "    !python demo/inferencer_demo.py {input_video} --black-background --pose2d human --vis-out-dir {output_dir}\n",
        "    print(f\"Skeleton created and saved to: /content/mmpose/{output_dir + '/' +  pose_dropdown.value}\")\n",
        "\n",
        "# Define a function to handle the button click event\n",
        "def get_input(event):\n",
        "    print(f\"User's prompt: {input_text.value}\")\n",
        "    display_loading()\n",
        "    display_video(\"input/\" + pose_dropdown.value)\n",
        "    display_message('This is the video you have selected!')\n",
        "\n",
        "    %cd /content/mmpose\n",
        "    save_skeleton()\n",
        "    display_message('Please View Skeleton at T20-11.')\n",
        "\n",
        "# Attach the function to the button's click event\n",
        "button.on_click(get_input)\n",
        "\n",
        "# Display the widgets\n",
        "display(section_label, pose_dropdown, button)"
      ],
      "metadata": {
        "id": "s8Vz1ZtPD3pR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating of YAML files for the input video** (T20-12)"
      ],
      "metadata": {
        "id": "oVW_VyBREcWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import yaml\n",
        "\n",
        "input_directory = '/content/mmpose/vis_results/posetrack18'\n",
        "video_files = []\n",
        "if os.path.exists(input_directory):\n",
        "  # Get a list of video files in the input directory\n",
        "  video_files = [os.path.join(input_directory, file) for file in os.listdir(input_directory) if file.endswith('.mp4')]\n",
        "\n",
        "# Create input widgets for configuration parameters\n",
        "config_name_input = widgets.Text(\n",
        "    value=\"configs/man-skiing.yaml\",\n",
        "    description=\"Config Name:\",\n",
        ")\n",
        "\n",
        "train_video_path_input = widgets.Dropdown(\n",
        "    options=video_files,\n",
        "    description='Select Video:'\n",
        ")\n",
        "\n",
        "train_prompt_input = widgets.Text(\n",
        "    value=\"a man is skiing\",\n",
        "    description=\"Train Prompt:\",\n",
        ")\n",
        "\n",
        "video_length_input = widgets.IntSlider(\n",
        "    value=8,\n",
        "    min=1,\n",
        "    max=30,\n",
        "    step=1,\n",
        "    description=\"Video Length:\",\n",
        ")\n",
        "\n",
        "width_input = widgets.IntSlider(\n",
        "    value=512,\n",
        "    min=128,\n",
        "    max=1024,\n",
        "    step=64,\n",
        "    description=\"Width:\",\n",
        ")\n",
        "\n",
        "height_input = widgets.IntSlider(\n",
        "    value=512,\n",
        "    min=128,\n",
        "    max=1024,\n",
        "    step=64,\n",
        "    description=\"Height:\",\n",
        ")\n",
        "\n",
        "learning_rate_input = widgets.FloatLogSlider(\n",
        "    value=3e-5,\n",
        "    base=10,\n",
        "    min=-5,\n",
        "    max=0,\n",
        "    step=0.1,\n",
        "    description=\"Learning Rate:\",\n",
        ")\n",
        "\n",
        "train_steps_input = widgets.IntSlider(\n",
        "    value=300,\n",
        "    min=100,\n",
        "    max=1000,\n",
        "    step=100,\n",
        "    description=\"Train Steps:\",\n",
        ")\n",
        "\n",
        "# Create a progress widget\n",
        "progress = widgets.FloatProgress(\n",
        "    value=0,\n",
        "    min=0,\n",
        "    max=100,\n",
        "    bar_style=\"success\"\n",
        ")\n",
        "\n",
        "def update_progress_bar():\n",
        "  progress.value += 35\n",
        "  time.sleep(1)\n",
        "\n",
        "\n",
        "# Create a button to generate the configuration\n",
        "generate_config_button = widgets.Button(\n",
        "    description=\"Generate Configuration\",\n",
        ")\n",
        "\n",
        "# Function to generate the configuration\n",
        "def generate_config(event):\n",
        "    # Get the full path of the configuration file\n",
        "    config_file_path = config_name_input.value\n",
        "\n",
        "    update_progress_bar()\n",
        "\n",
        "    # Ensure that the directory for the configuration file exists\n",
        "    config_directory = os.path.dirname(config_file_path)\n",
        "    os.makedirs(config_directory, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "    config = {\n",
        "        \"train_data\": {\n",
        "            \"video_path\": train_video_path_input.value,\n",
        "            \"prompt\": train_prompt_input.value,\n",
        "            \"n_sample_frames\": video_length_input.value,\n",
        "            \"width\": width_input.value,\n",
        "            \"height\": height_input.value,\n",
        "            \"sample_start_idx\": 0,\n",
        "            \"sample_frame_rate\": 2,\n",
        "        },\n",
        "        \"validation_data\": {\n",
        "            \"prompts\": [\n",
        "                \"mickey mouse is skiing on the snow\",\n",
        "                \"spider man is skiing on the beach, cartoon style\",\n",
        "                \"wonder woman, wearing a cowboy hat, is skiing\",\n",
        "                \"a man, wearing pink clothes, is skiing at sunset\",\n",
        "            ],\n",
        "            \"video_length\": video_length_input.value,\n",
        "            \"width\": width_input.value,\n",
        "            \"height\": height_input.value,\n",
        "            \"num_inference_steps\": 20,\n",
        "            \"guidance_scale\": 12.5,\n",
        "            \"use_inv_latent\": True,\n",
        "            \"num_inv_steps\": 50,\n",
        "        },\n",
        "        \"learning_rate\": learning_rate_input.value,\n",
        "        \"train_batch_size\": 1,\n",
        "        \"max_train_steps\": train_steps_input.value,\n",
        "        \"checkpointing_steps\": 1000,\n",
        "        \"validation_steps\": 100,\n",
        "        \"trainable_modules\": [\n",
        "            \"attn1.to_q\",\n",
        "            \"attn2.to_q\",\n",
        "            \"attn_temp\",\n",
        "        ],\n",
        "        \"seed\": 33,\n",
        "        \"mixed_precision\": \"fp16\",\n",
        "        \"use_8bit_adam\": False,\n",
        "        \"gradient_checkpointing\": True,\n",
        "        \"enable_xformers_memory_efficient_attention\": True,\n",
        "    }\n",
        "    generate_config_button.description = \"Completed\"\n",
        "    generate_config_button.disabled = True\n",
        "\n",
        "    update_progress_bar()\n",
        "\n",
        "    # Save the configuration as a YAML file\n",
        "    with open(config_file_path, 'w') as config_file:\n",
        "        yaml.dump(config, config_file)\n",
        "\n",
        "    update_progress_bar()\n",
        "# Attach event handler to the generate button\n",
        "generate_config_button.on_click(generate_config)\n",
        "\n",
        "# Display input widgets and generate button\n",
        "display(config_name_input)\n",
        "display(train_video_path_input)\n",
        "display(train_prompt_input)\n",
        "display(video_length_input)\n",
        "display(width_input)\n",
        "display(height_input)\n",
        "display(learning_rate_input)\n",
        "display(train_steps_input)\n",
        "display(generate_config_button)\n",
        "display(progress)"
      ],
      "metadata": {
        "id": "dtjLWdesEfVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Model Section** (T20-12)"
      ],
      "metadata": {
        "id": "zm2uxGHZF8F6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import ipywidgets as widgets\n",
        "import yaml\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm  # For the loading bar\n",
        "\n",
        "# Specify your dataset directory in Google Colab\n",
        "dataset_dir = '/content/dataset'\n",
        "\n",
        "# Get a list of subfolders in the dataset directory\n",
        "subfolders = [f for f in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, f))]\n",
        "\n",
        "# Create a dropdown widget to choose a subfolder\n",
        "subfolder_dropdown = widgets.Dropdown(\n",
        "    options=subfolders,\n",
        "    description='Select Subfolder:'\n",
        ")\n",
        "\n",
        "# Display the dropdown to the user\n",
        "display(subfolder_dropdown)\n",
        "\n",
        "# Input field for specifying the model name\n",
        "model_name_input = widgets.Text(\n",
        "    placeholder='Enter Model Name',\n",
        "    description='Model Name:'\n",
        ")\n",
        "\n",
        "# Display the input field for the model name\n",
        "display(model_name_input)\n",
        "\n",
        "# Initialize an empty list to store video properties\n",
        "video_properties_list = []\n",
        "\n",
        "# Define a function to generate a YAML configuration based on video properties\n",
        "def generate_yaml_config(video_properties_list, model_name, subfolder):\n",
        "    if not video_properties_list:\n",
        "        print(\"No video properties found. Training aborted.\")\n",
        "        return\n",
        "\n",
        "    config = {\n",
        "        'pretrained_model_path': \"./checkpoints/stable-diffusion-v1-4\",\n",
        "        'output_dir': \"output\",\n",
        "        'train_data': {\n",
        "            'video_path': \"no path\",\n",
        "            'prompt': \"None\",\n",
        "            'n_sample_frames': 12,\n",
        "            'width': 512,\n",
        "            'height': 512,\n",
        "            'sample_start_idx': 0,\n",
        "            'sample_frame_rate': 4,\n",
        "            'dataset_set': \"train\"\n",
        "        },\n",
        "        'validation_data': {\n",
        "            'prompts': [\n",
        "                'A Iron man on the beach',\n",
        "                'A Spider man on the snow',\n",
        "                'A Superman on the street',\n",
        "                'A boy in the forest'\n",
        "            ],\n",
        "            'video_length': 24,\n",
        "            'width': 512,\n",
        "            'height': 512,\n",
        "            'num_inference_steps': 50,\n",
        "            'guidance_scale': 12.5,\n",
        "            'use_inv_latent': False,\n",
        "            'num_inv_steps': 50,\n",
        "            'dataset_set': \"val\"\n",
        "        },\n",
        "        'learning_rate': 3e-5,\n",
        "        'train_batch_size': 1,\n",
        "        'max_train_steps': 5000,\n",
        "        'checkpointing_steps': 1000,\n",
        "        'validation_steps': 100,\n",
        "        'trainable_modules': [\n",
        "            \"attn1.to_q\",\n",
        "            \"attn2.to_q\",\n",
        "            \"attn_temp\",\n",
        "            \"conv_temporal\"\n",
        "        ],\n",
        "        'skeleton_path': './pose_example/vis_kun_pose2.mov',\n",
        "        'seed': 33,\n",
        "        'mixed_precision': 'no',\n",
        "        'use_8bit_adam': False,\n",
        "        'gradient_checkpointing': False,\n",
        "        'enable_xformers_memory_efficient_attention': True\n",
        "    }\n",
        "\n",
        "    # Define the output YAML file path\n",
        "    output_yaml_path = os.path.join('/content/configs', f'{model_name}_{subfolder}_config.yaml')\n",
        "\n",
        "    # Save the configuration dictionary to a YAML file\n",
        "    with open(output_yaml_path, 'w') as yaml_file:\n",
        "        yaml.dump(config, yaml_file)\n",
        "\n",
        "    print(f'Configuration saved to {output_yaml_path}')\n",
        "\n",
        "# Define a button to trigger training\n",
        "train_button = widgets.Button(\n",
        "    description='Train Model'\n",
        ")\n",
        "\n",
        "# Function to handle button click event\n",
        "def train_button_click(b):\n",
        "    subfolder = subfolder_dropdown.value\n",
        "    model_name = model_name_input.value\n",
        "\n",
        "    # Iterate through videos in the selected subfolder\n",
        "    subfolder_path = os.path.join(dataset_dir, subfolder)\n",
        "    video_files = [f for f in os.listdir(subfolder_path) if f.endswith('.mp4')]\n",
        "\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(subfolder_path, video_file)\n",
        "\n",
        "        # Extract video properties and add to the list\n",
        "        video_properties = {\n",
        "            'video_path': video_path,\n",
        "            'width': 512,  # Replace with actual video width\n",
        "            'height': 512,  # Replace with actual video height\n",
        "            'sample_frame_rate': 30,  # Replace with actual frame rate\n",
        "            'duration': 300,  # Replace with actual video duration\n",
        "            'n_sample_frames': 12,\n",
        "            'sample_start_idx': 0\n",
        "        }\n",
        "        video_properties_list.append(video_properties)\n",
        "\n",
        "    # Generate YAML config based on aggregated video properties\n",
        "    generate_yaml_config(video_properties_list, model_name, subfolder)\n",
        "    # Add your training logic here using the generated YAML config for all videos\n",
        "\n",
        "    # Simulate training with a loading bar (replace this with your actual training code)\n",
        "    num_epochs = config.get(\"num_epochs\", 10)  # Number of training epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        # Create a loading bar\n",
        "        progress_bar = tqdm(total=num_epochs, position=0, leave=True)\n",
        "        progress_bar.set_description(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        for _ in range(10):  # Simulate training steps\n",
        "            progress_bar.update(1)  # Update the loading bar\n",
        "            import time\n",
        "            time.sleep(0.1)  # Simulate a training step\n",
        "        progress_bar.close()\n",
        "        # Add \"Training completed\" message\n",
        "    print('Training completed')\n",
        "\n",
        "# Attach the click event handler to the training button\n",
        "train_button.on_click(train_button_click)\n",
        "\n",
        "# Display the training button\n",
        "display(train_button)"
      ],
      "metadata": {
        "id": "eTQE4kxuF9Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING FOR YAML"
      ],
      "metadata": {
        "id": "lDKZtfqjGC2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Load the YAML configuration file\n",
        "config_file_path = \"/content/drive/My Drive/man-skiing.yaml\"  # Replace with the actual path\n",
        "with open(config_file_path, 'r') as config_file:\n",
        "    config = yaml.safe_load(config_file)"
      ],
      "metadata": {
        "id": "a6bFmqE0GBM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Use OpenCV to read and process the video\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2  # Import the OpenCV library\n",
        "\n",
        "video_path = config[\"train_data\"][\"video_path\"]\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Process the frame here (e.g., apply image processing)\n",
        "\n",
        "    # Display or save the processed frame\n",
        "    cv2_imshow(frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "oEU9RGsFGETH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specify Text Prompt as input to GenAI model and see inference results in the form of output videos with captions depicting action/activity, so that I can access model's quality. (T20-11)"
      ],
      "metadata": {
        "id": "nVtaHo-pGe-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Viewing Video Reference based on config and prompt\n",
        "# Pose - Viewing Skeleton Reference\n",
        "# %pip install ipywidgets\n",
        "%cd /content/mmpose\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "from base64 import b64encode\n",
        "import time  # Import the time module\n",
        "import subprocess\n",
        "\n",
        "# add dropdown to allow selection of poses\n",
        "list_of_poses = []\n",
        "input_folder = \"../input\"\n",
        "if os.path.exists(input_folder):\n",
        "  for file in os.listdir(input_folder):\n",
        "    if file.endswith(\".mp4\"):\n",
        "        list_of_poses.append(file)\n",
        "\n",
        "# Widget Dropdown\n",
        "pose_dropdown = widgets.Dropdown(\n",
        "    options=list_of_poses,\n",
        "    description='Select a MP4 File:'\n",
        ")\n",
        "\n",
        "section_label = widgets.HTML(value='<h2 style=\"font-size: 20px;\">View Reference as Video</h2>')\n",
        "\n",
        "input_label = widgets.Label(value=\"Enter your prompt:\") # Label for the Input Field Widget\n",
        "input_text = widgets.Text(placeholder='eg. A Man is skiing') # Input Field Widget for User to enter prompt\n",
        "prompt_input_box = widgets.HBox([input_label, input_text])\n",
        "\n",
        "# Create a button widget\n",
        "button = widgets.Button(description=\"View Reference\")\n",
        "\n",
        "def display_video(video_path):\n",
        "    with open(video_path, \"rb\") as f:\n",
        "        video_data = f.read()\n",
        "        video_base64 = b64encode(video_data).decode(\"utf-8\")\n",
        "        video_html = f'<video controls width=\"400\"><source src=\"data:video/mp4;base64,{video_base64}\" type=\"video/mp4\"></video>'\n",
        "        display(HTML(video_html))\n",
        "    display_success('Video Generated!')\n",
        "\n",
        "def display_loading():\n",
        "    loading_message = HTML('<p>Video Generating... Please Wait...</p>')\n",
        "    display(loading_message)\n",
        "    # Simulate video generation with a sleep (replace this with your actual video generation logic)\n",
        "    time.sleep(3)  # Sleep for 3 seconds [Will help to let users know the video is generating.]\n",
        "\n",
        "# Annouce to user that video is done and can input another prompt\n",
        "def display_success(message):\n",
        "    loading_message = HTML('<p>' + message + '</p>')\n",
        "    display(loading_message)\n",
        "\n",
        "# Define a function to handle the button click event\n",
        "def get_input(event):\n",
        "    print(f\"User's prompt: {input_text.value}\")\n",
        "    display_loading()\n",
        "    display_video(\"input/\" + pose_dropdown.value)\n",
        "    %cd /content/mmpose\n",
        "    display_video('vis_results/posetrack18/' + pose_dropdown.value)\n",
        "\n",
        "# Attach the function to the button's click event\n",
        "button.on_click(get_input)\n",
        "\n",
        "# Display the widgets\n",
        "display(section_label, pose_dropdown, prompt_input_box, button)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zsROdawJGfd5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BfEDCST37J88",
        "NlyqeKWQ5vGn",
        "P-o9mSNTnoAR",
        "ckPnQEjYOT_v",
        "71UCdwBu_1WA"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}